{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture. \n",
    "\n",
    "Imagine that we want to compete on Jeopardy, and we're looking for any way to win. In this project, we'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help us win.\n",
    "\n",
    "The dataset is named `jeopardy.csv`, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which can be downloaded [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file).\n",
    "\n",
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n",
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "print(jeopardy.head())\n",
    "\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
      "       'Answer'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "Show Number    19999 non-null int64\n",
      "Air Date       19999 non-null object\n",
      "Round          19999 non-null object\n",
      "Category       19999 non-null object\n",
      "Value          19999 non-null object\n",
      "Question       19999 non-null object\n",
      "Answer         19999 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Removing leading and trailing spaces\n",
    "jeopardy.columns = jeopardy.columns.str.strip()\n",
    "print(jeopardy.columns)\n",
    "\n",
    "print(jeopardy.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing text\n",
    "\n",
    "Before we can analyse the Jeopardy columns, we need to normalize all of the text columns. Therefore we will remove all punctuation and put all words in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to normalize strings\n",
    "\n",
    "import re\n",
    "\n",
    "def normalize_text(string):\n",
    "    \"\"\"Takes a string as an input, transforms it to lowercase and removes punctuation\"\"\"\n",
    "    string = string.lower()\n",
    "    string = re.sub(r'\\W', ' ', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    for the last 8 years of his life  galileo was ...\n",
       "1    no  2  1912 olympian  football star at carlisl...\n",
       "2    the city of yuma in this state has a record av...\n",
       "3    in 1963  live on  the art linkletter show   th...\n",
       "4    signer of the dec  of indep   framer of the co...\n",
       "Name: clean_question, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to the Question column\n",
    "\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\n",
    "jeopardy['clean_question'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    copernicus\n",
       "1    jim thorpe\n",
       "2       arizona\n",
       "3    mcdonald s\n",
       "4    john adams\n",
       "Name: clean_answer, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to the Answer column\n",
    "\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)\n",
    "jeopardy['clean_answer'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing columns\n",
    "\n",
    "The `Value` column should be numeric, to allow us to manipulate it easier. We'll need to remove the dollar sign from the beginning of each value and convert the column from text to numeric.\n",
    "\n",
    "The `Air Date` column should also be a datetime, not a string, to enable us to work it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "2    200\n",
       "3    200\n",
       "4    200\n",
       "Name: clean_value, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to normalize dollar values\n",
    "\n",
    "def normalize_dollars(string):\n",
    "    \"\"\"Takes in a string as an input, removes the dollar sign and returns an integer\"\"\"\n",
    "    if not string or string == 'None':\n",
    "        return 0\n",
    "        print(\"Some erroneous values have been replaced with 0.\")\n",
    "    try:\n",
    "        string = re.sub(r'\\$', '', string)\n",
    "        string = re.sub(r'\\W', '', string)\n",
    "    except ValueError:\n",
    "        string = 0\n",
    "        print(\"Some erroneous values have been replaced with 0.\")\n",
    "    return int(string)\n",
    "\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_dollars)\n",
    "jeopardy['clean_value'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2004-12-31\n",
       "1   2004-12-31\n",
       "2   2004-12-31\n",
       "3   2004-12-31\n",
       "4   2004-12-31\n",
       "Name: Air Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Air Date to datetime\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])\n",
    "jeopardy['Air Date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers in questions\n",
    "\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "- How often the answer can be used for a question.\n",
    "- How often questions are repeated.\n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. We can answer the first question by seeing how many times words in the answer also occur in the question. We'll work on the first question and come back to the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to match terms occuring in the answers to questions\n",
    "\n",
    "def match_count(clean_answer, clean_question):\n",
    "    \"\"\"Takes in the cleaned answer and the question, splits them into words, and counts recurring matches.\"\"\"\n",
    "    \n",
    "    # Split both into lists of words\n",
    "    split_answer = clean_answer.split()  \n",
    "    split_question = clean_question.split()  \n",
    "\n",
    "    # Remove instances of 'the'\n",
    "    split_answer = [word for word in split_answer if word != 'the']\n",
    "    \n",
    "    if len(split_answer) == 0:\n",
    "        return 0  # Return 0 if answer is empty \n",
    "    \n",
    "    # Count matches\n",
    "    match_count = 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    \n",
    "    return match_count / len(split_answer)  # Normalize by the length of the answer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06229526885934705\n"
     ]
    }
   ],
   "source": [
    "# Count how many terms in clean_answer occur in clean_question\n",
    "\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(lambda row: match_count(row['clean_answer'], row['clean_question']), axis=1)\n",
    "print(jeopardy['answer_in_question'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mean tells us that on average, the answer makes up for about 6% of the question. So if our strategy would be to recycle content from what we hear in the question, we would not be very successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recycled questions\n",
    "\n",
    "But we might be able to exploit the fact that questions are being recycled, i.e. they are repeats of old ones.  \n",
    "We can't completely answer this, because we only have about 10% of the full Jeopardy question dataset, but we \n",
    "can investigate it at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7197989717809739\n"
     ]
    }
   ],
   "source": [
    "# Check for question overlap over time\n",
    "\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "jeopardy = jeopardy.sort_values('Air Date')\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(' ') # split into words\n",
    "    split_question = [question for question in split_question if len(question) > 5] # remove questions with fewer than 6 words\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "\n",
    "jeopardy['question_overlap'] = question_overlap\n",
    "print(jeopardy['question_overlap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is about a 72% overlap between terms in new questions and terms in old questions. This only looks at a small set of questions, and it doesn't look at phrases â€” it looks at single terms. This makes it relatively insignificant, but it does mean that it might be worth looking more into the recycling of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-value vs. high-value questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's say we only want to study questions that pertain to high value questions instead of low value questions. This will help us earn more money when we're on Jeopardy.\n",
    "\n",
    "We can actually figure out which terms correspond to high-value questions using a chi-squared test. We'll first need to narrow down the questions into two categories:\n",
    "\n",
    "- Low value -- Any row where Value is less than 800.\n",
    "- High value -- Any row where Value is greater than 800.\n",
    "\n",
    "We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19325    0\n",
      "19301    0\n",
      "19302    0\n",
      "19303    0\n",
      "19304    0\n",
      "Name: high_value, dtype: int64\n",
      "0.28671433571678584\n"
     ]
    }
   ],
   "source": [
    "# Function to determine high and low value questions\n",
    "\n",
    "def high_low(row):\n",
    "    \"\"\"Function to determine formulations in high- and low-value questions.\"\"\"\n",
    "    if row > 800:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply to clean_value column\n",
    "jeopardy['high_value'] = jeopardy['clean_value'].apply(high_low)\n",
    "print(jeopardy['high_value'].head())\n",
    "print(jeopardy['high_value'].mean())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connecting words and value\n",
    "\n",
    "def high_low_count(word):\n",
    "    \"\"\"Function to determine which words show up in high or low value questions.\"\"\"\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question'].split() # split into words\n",
    "        if word in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 1), (1, 0), (2, 1), (1, 0), (1, 1), (0, 1), (1, 0), (0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Select sample of comparison terms\n",
    "\n",
    "from random import choice\n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)]\n",
    "\n",
    "# Calculate the observed and expected counts\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(high_low_count(term))\n",
    "\n",
    "print(observed_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the chi-squred test\n",
    "\n",
    "Now that we've found the observed counts for a few terms, we can compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469), Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469), Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047), Power_divergenceResult(statistic=2.1177104383031944, pvalue=0.14560406868264344), Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047), Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996), Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469), Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047), Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469), Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996)]\n"
     ]
    }
   ],
   "source": [
    "## Applying the chi-squared test\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "print(chi_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
